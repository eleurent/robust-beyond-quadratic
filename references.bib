@book{pena2008self,
  title={Self-normalized processes: Limit theory and Statistical Applications},
  author={Pe{\~n}a, Victor H and Lai, Tze Leung and Shao, Qi-Man},
  year={2008},
  publisher={Springer Science \& Business Media}
}

@inproceedings{leurent2019interval,
	author    = {Leurent, E. and Efimov, D. and Ra\"issi, T. and Perruquetti, W.},
	title     = {Interval Prediction for Continuous-Time Systems with Parametric Uncertainties},
	booktitle = {Proc. IEEE Conference on Decision and Control (CDC)},
	year      = {2019},
	address   = {Nice},
}

@article{Efimov2013,
  author = {Efimov, D. and Ra\"issi, T. and Chebotarev, S. and Zolghadri, A.},
  title = {Interval State Observer for Nonlinear Time Varying Systems},
  journal = {Automatica},
  year = {2013},
  volume = {49},
  pages = {200--205},
  number = {1},
  owner = {EfDe},
  timestamp = {2013.01.08}
}

@unpublished{maillard2016,
  TITLE = {{Self-normalization techniques for streaming confident regression}},
  AUTHOR = {Maillard, Odalric-Ambrym},
  URL = {https://hal.archives-ouvertes.fr/hal-01349727},
  NOTE = {working paper or preprint},
  YEAR = {2016},
  MONTH = May,
  KEYWORDS = {regression ; dependent variables ; Concentration inequalities ; self-normalized ; sequential prediction},
  HAL_ID = {hal-01349727},
  HAL_VERSION = {v1},
}

@incollection{Abbasi2011,
title = {Improved Algorithms for Linear Stochastic Bandits},
author = {Yasin Abbasi-Yadkori and P\'{a}l, D\'{a}vid and Csaba Szepesv\'{a}ri},
booktitle = {Advances in Neural Information Processing Systems 24},
editor = {J. Shawe-Taylor and R. S. Zemel and P. L. Bartlett and F. Pereira and K. Q. Weinberger},
pages = {2312--2320},
year = {2011},
publisher = {Curran Associates, Inc.},
}


@InProceedings{abbasi-yadkori11a,
  title = 	 {Regret Bounds for the Adaptive Control of Linear Quadratic Systems},
  author = 	 {Yasin Abbasi-Yadkori and Csaba Szepesvári},
  booktitle = 	 {Proceedings of the 24th Annual Conference on Learning Theory},
  pages = 	 {1--26},
  year = 	 {2011},
  editor = 	 {Sham M. Kakade and Ulrike von Luxburg},
  volume = 	 {19},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Budapest, Hungary},
  month = 	 {09--11 Jun},
  publisher = 	 {PMLR},
}

@InProceedings{abeille18a,
  title = 	 {Improved Regret Bounds for Thompson Sampling in Linear Quadratic Control Problems},
  author = 	 {Abeille, Marc and Lazaric, Alessandro},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1--9},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR},
  abstract = 	 {Thompson sampling (TS) is an effective approach to trade off exploration and exploration in reinforcement learning. Despite its empirical success and recent advances, its theoretical analysis is often limited to the Bayesian setting, finite state-action spaces, or finite-horizon problems. In this paper, we study an instance of TS in the challenging setting of the infinite-horizon linear quadratic (LQ) control, which models problems with continuous state-action variables, linear dynamics, and quadratic cost. In particular, we analyze the regret in the frequentist sense (i.e., for a fixed unknown environment) in one-dimensional systems. We derive the first $O(\sqrt{T})$ frequentist regret bound for this problem, thus significantly improving the $O(T^{2/3})$ bound of Abeille & Lazaric (2017) and matching the frequentist performance derived by Abbasi-Yadkori & Szepesvári (2011) for an optimistic approach and the Bayesian result Ouyang et al. (2017) We obtain this result by developing a novel bound on the regret due to policy switches, which holds for LQ systems of any dimensionality and it allows updating the parameters and the policy at each step, thus overcoming previous limitations due to lazy updates. Finally, we report numerical simulations supporting the conjecture that our result extends to multi-dimensional systems.}
}

@article{Dean2017,
  title={On the Sample Complexity of the Linear Quadratic Regulator},
  author={Sarah Dean and Horia Mania and Nikolai Matni and Benjamin Recht and Stephen Tu},
  journal={ArXiv},
  year={2017},
  volume={abs/1710.01688}
}

@incollection{Dean2018,
title = {Regret Bounds for Robust Adaptive Control of the Linear Quadratic Regulator},
author = {Dean, Sarah and Mania, Horia and Matni, Nikolai and Recht, Benjamin and Tu, Stephen},
booktitle = {Advances in Neural Information Processing Systems 31},
editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
pages = {4188--4197},
year = {2018},
publisher = {Curran Associates, Inc.},
}

@Article{Lu1997,
	author={Lu, Xiao-Yun
	and Spurgeon, Sarah K.},
	title={Robust sliding mode control of uncertain nonlinear systems},
	journal={Systems {\&} Control Letters},
	year={1997},
	month={Nov},
	day={03},
	volume={32},
	number={2},
	pages={75-90},
	keywords={Robustness; Sliding mode control; Dynamic feedback; Zero dynamics; Uniform ultimate boundedness},
	abstract={A dynamic sliding mode controller design method is proposed for multiple input-output systems with additive uncertainties. A previous result on the stability of triangular systems is generalised to the case of uniform ultimate boundedness of controlled triangular systems. This is used to prove the stability of the overall closed-loop system. The uncertain system with appropriately chosen sliding mode control is shown to be ultimately bounded if the zero dynamics of the nominal system are uniformly asymptotically (exponentially) stable. The design method is demonstrated with two examples.},
	issn={0167-6911},
}

@INPROCEEDINGS{Lopez2019,
	author={B. T. {Lopez} and J. E. {Slotine} and J. P. {How}},
	booktitle={2019 American Control Conference (ACC)}, 
	title={Dynamic Tube MPC for Nonlinear Systems}, 
	year={2019},
	volume={},
	number={},
	pages={1655-1662},
}

@article{Limon2010,
	abstract = {This paper is devoted to solve the problem that the predictive controllers may present when the target operation point changes. Model predictive controllers (MPC) are capable to steer an uncertain system to a given target operation point fulfilling the constraints. But if the target changes significantly the controller may not success due to the loss of feasibility of the optimization problem and the inadequacy of the terminal conditions. This paper presents a novel formulation of a robust model predictive controller (MPC) for tracking changing targets based on a single optimization problem. The plant is assumed to be modelled as a linear system with additive uncertainties confined to a bounded known polyhedral set. Under mild assumptions, the proposed MPC is feasible under any change of the target and steers the uncertain system to (a neighborhood of) the target if this is admissible. If the target is not admissible, and hence unreachable, the system is steered to the closest admissible operating point. The controller formulation has some parameters which provide extra degrees of freedom. These new parameters allow control objectives such as disturbance rejection, output offset prioritization or enlargement of the domain of attraction to be dealt with. The paper shows how these parameters can be calculated off-line. In order to demonstrate the benefits of the proposed controller, it has been tested on a real plant: the four tanks plant which is a multivariable nonlinear system configured to exhibit non-minimum phase transmission zeros. Experimental results show the robust stability and offset-free tracking of the controlled plant. {\textcopyright} 2009 Elsevier Ltd. All rights reserved.},
	author = {Limon, D. and Alvarado, I. and Alamo, T. and Camacho, E. F.},
	doi = {10.1016/j.jprocont.2009.11.007},
	issn = {09591524},
	journal = {Journal of Process Control},
	keywords = {Constrained linear systems,Model predictive control,Offset-free,Robust control,Tracking},
	title = {{Robust tube-based MPC for tracking of constrained linear systems with additive disturbances}},
	year = {2010}
}


@inproceedings{Turchetta2016,
	abstract = {In classical reinforcement learning agents accept arbitrary short term loss for long term gain when exploring their environment. This is infeasible for safety critical applications such as robotics, where even a single unsafe action may cause system failure or harm the environment. In this paper, we address the problem of safely exploring finite Markov decision processes (MDP). We define safety in terms of an a priori unknown safety constraint that depends on states and actions and satisfies certain regularity conditions expressed via a Gaussian process prior. We develop a novel algorithm, SAFEMDP, for this task and prove that it completely explores the safely reachable part of the MDP without violating the safety constraint. To achieve this, it cautiously explores safe states and actions in order to gain statistical confidence about the safety of unvisited state-action pairs from noisy observations collected while navigating the environment. Moreover, the algorithm explicitly considers reachability when exploring the MDP, ensuring that it does not get stuck in any state with no safe way out. We demonstrate our method on digital terrain models for the task of exploring an unknown map with a rover.},
	archivePrefix = {arXiv},
	arxivId = {1606.04753},
	author = {Turchetta, Matteo and Berkenkamp, Felix and Krause, Andreas},
	booktitle = {Advances in Neural Information Processing Systems},
	eprint = {1606.04753},
	issn = {10495258},
	title = {{Safe exploration in finite Markov decision processes with Gaussian processes}},
	year = {2016}
}

@inproceedings{kirschner18heteroscedastic,
	Author = {Johannes Kirschner and Andreas Krause},
	Booktitle = {Proc. International Conference on Learning Theory (COLT)},
	Month = {July},
	Title = {Information Directed Sampling and Bandits with Heteroscedastic Noise},
	Year = {2018}}
	
@unpublished{maillard:hal-01349727,
  TITLE = {{Self-normalization techniques for streaming confident regression}},
  AUTHOR = {Maillard, Odalric-Ambrym},
  URL = {https://hal.archives-ouvertes.fr/hal-01349727},
  NOTE = {working paper or preprint},
  YEAR = {2016},
  MONTH = May,
  KEYWORDS = {regression ; dependent variables ; Concentration inequalities ; sequential prediction ; self-normalized},
  PDF = {https://hal.archives-ouvertes.fr/hal-01349727/file/HalSubmittedV2.pdf},
  HAL_ID = {hal-01349727},
  HAL_VERSION = {v2},
}

@inproceedings{Hren2008,
	title = {{Optimistic planning of deterministic systems}},
	author = {Hren, Jean-Francois and Munos, R{\'e}mi},
	booktitle = {{European Workshop on Reinforcement Learning}},
	address = {France},
	pages = {151-164},
	year = {2008},
	hal_id = {hal-00830182},
	hal_version = {v1},
}

@article{Schneider1997,
author = {Schneider, JG},
journal = {Advances in neural information processing systems},
pages = {1047----1053},
title = {{Exploiting model uncertainty estimates for safe dynamic control learning}},
year = {1997}
}

@article{delos2015,
  TITLE = {{Minkowski Sum of Polytopes Defined by Their Vertices}},
  AUTHOR = {Delos, Vincent and Teissandier, Denis},
  JOURNAL = {{Journal of Applied Mathematics and Physics (JAMP)}},
  VOLUME = {3},
  NUMBER = {1},
  PAGES = {62-67},
  YEAR = {2015},
  MONTH = Jan,
}


@article{Iyengar2005,
	author = {Iyengar, Garud N.},
	journal = {Mathematics of Operations Research},
	pages = {257--280},
	title = {{Robust Dynamic Programming}},
	volume = {30},
	year = {2005}
}

@article{Nilim2005,
	author = {Nilim, Arnab and {El Ghaoui}, Laurent},
	journal = {Operations Research},
	pages = {780--798},
	title = {{Robust Control of Markov Decision Processes with Uncertain Transition Matrices}},
	volume = {53},
	year = {2005}
}

@article{Wiesemann2013,
	author = {Wiesemann, Wolfram and Kuhn, Daniel and Rustem, Ber{\c{c}}},
	journal = {Mathematics of Operations Research},
	mendeley-groups = {Robust Control},
	pages = {1--52},
	title = {{Robust Markov Decision Processes}},
	year = {2013}
}

@misc{highway-env,
	author = {Leurent, Edouard},
	title = {An Environment for Autonomous Driving Decision-Making},
	year = {2018},
	publisher = {GitHub},
	journal = {GitHub repository},
	howpublished = {\url{https://github.com/eleurent/highway-env}},
}

@article {Silver1140,
	author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
	title = {A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
	volume = {362},
	number = {6419},
	pages = {1140--1144},
	year = {2018},
	publisher = {American Association for the Advancement of Science},
	journal = {Science}
}

@article{mnih2015humanlevel,
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	journal = {Nature},
	month = feb,
	number = 7540,
	pages = {529--533},
	publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	title = {Human-level control through deep reinforcement learning},
	volume = 518,
	year = 2015
}

@book{Basar1996,
	author = {Basar, T. and Bernhard, P.},
	booktitle = {IEEE Transactions on Automatic Control},
	pages = {411},
	title = {{H infinity - Optimal Control and Related Minimax Design Problems: A Dynamic Game Approach}},
	volume = {41},
	year = {1996}
}

@inproceedings{busoniu2013,
	author = {Busoniu, Lucian and Daniels, Alexander and Munos, Remi and Babuska, Robert},
	year = {2013},
	month = {04},
	booktitle = {IEEE International Symposium on Adaptive Dynamic Programming and Reinforcement Learning},
	title = {Optimistic Planning for Continuous-Action Deterministic Systems},
}

@inproceedings{Mansley2011,
	author = {Mansley, Chris and Weinstein, Ari and Littman, Michael},
	year = {2011},
	month = {01},
	title = {Sample-Based Planning for Continuous Action Markov Decision Processes.},
	journal = {Proceedings of the 21st International Conference on Automated Planning and Scheduling}
}

@article{Weinstein2012,
	author = {Weinstein, A. and Littman, M.L.},
	year = {2012},
	month = {01},
	pages = {306-314},
	title = {Bandit-based planning and learning in continuous-action markov decision processes},
	journal = {Proceedings of the 22nd International Conference on Automated Planning and Scheduling}
}

@article{Busoniu2018,
	author = {Busoniu, Lucian and Pall, Elod and Munos, Remi},
	year = {2018},
	month = {06},
	pages = {100-108},
	title = {Continuous-action planning for discounted infinite-horizon nonlinear optimal control with Lipschitz values},
	volume = {92},
	journal = {Automatica},
}

@ARTICLE{Efimov2012,
	author = {Efimov, D. and Fridman, L.M. and Ra\"issi, T. and Zolghadri, A. and
	Seydou, R.},
	title = {Interval Estimation for {LPV} Systems Applying High Order Sliding
	Mode Techniques},
	journal = {Automatica},
	year = {2012},
	volume = {48},
	pages = {2365--2371},
}

@article{Kumar2013,
	title = {Robust LQR Controller Design for Stabilizing and Trajectory Tracking of Inverted Pendulum},
	journal = {Procedia Engineering},
	volume = {64},
	pages = {169 - 178},
	year = {2013},
	note = {International Conference on Design and Manufacturing},
	author = {E. Vinodh Kumar and Jovitha Jerome}
}

@inproceedings{Lenz2015,
	title={DeepMPC: Learning Deep Latent Features for Model Predictive Control},
	author={Ian Lenz and Ross A. Knepper and Ashutosh Saxena},
	booktitle={Robotics: Science and Systems},
	year={2015}
}

@article{Levine2015,
	author    = {Sergey Levine and
	Chelsea Finn and
	Trevor Darrell and
	Pieter Abbeel},
	title     = {End-to-End Training of Deep Visuomotor Policies},
	journal   = {CoRR},
	volume    = {abs/1504.00702},
	year      = {2015},
	archivePrefix = {arXiv},
	eprint    = {1504.00702}
}

@book{Bental2009,
	title={Robust optimization},
	author={Ben-Tal, Aharon and El Ghaoui, Laurent and Nemirovski, Arkadi},
	volume={28},
	year={2009},
	publisher={Princeton University Press}
}
@article{Bertsimas2011,
	title={Theory and applications of robust optimization},
	author={Bertsimas, Dimitris and Brown, David B and Caramanis, Constantine},
	journal={SIAM review},
	volume={53},
	number={3},
	pages={464--501},
	year={2011},
	publisher={SIAM}
}

@article{Gorissen2015,
	title = {A practical guide to robust optimization},
	journal = {Omega},
	volume = {53},
	pages = {124 - 137},
	year = {2015},
	author = {Bram L. Gorissen and İhsan Yanıkoğlu and Dick den Hertog},
}

@phdthesis{le2012,
	TITLE = {Robust predictive control by zonotopic set-membership estimation.},
	AUTHOR = {Le, Vu Tuan Hieu},
	NUMBER = {2012SUPL0016},
	SCHOOL = {{Sup{\'e}lec}},
	YEAR = {2012},
	MONTH = Oct,
	KEYWORDS = {Uncertain system ; Model predictive control ; Set-membership estimation ; Syst{\`e}me incertain ; Estimation ensembliste ; Zonotope ; Commande pr{\'e}dictive},
	TYPE = {Theses}
}

@article{Ibrahimi2013,
	author = {Ibrahimi, Morteza and Javanmard, Adel and Roy, Benjamin},
	year = {2013},
	month = {03},
	title = {Efficient Reinforcement Learning for High Dimensional Linear Quadratic Systems},
	volume = {4},
	journal = {Advances in Neural Information Processing Systems}
}

@article{Faradonbeh2017,
	author    = {Mohamad Kazem Shirani Faradonbeh and Ambuj Tewari and George Michailidis},
	title     = {Finite Time Analysis of Optimal Adaptive Policies for Linear-Quadratic
	Systems},
	journal   = {CoRR},
	volume    = {abs/1711.07230},
	year      = {2017},
	archivePrefix = {arXiv},
	eprint    = {1711.07230},
}

@article{Ouyang2017,
	author    = {Yi Ouyang and
	Mukul Gagrani and
	Rahul Jain},
	title     = {Learning-based Control of Unknown Linear Systems with Thompson Sampling},
	journal   = {CoRR},
	volume    = {abs/1709.04047},
	year      = {2017},
	archivePrefix = {arXiv},
	eprint    = {1709.04047},
}

@article{Sastry1990,
	abstract = {This volume surveys the major results and techniques of analysis in the field of adaptive control. Focusing on linear, continuous time, single-input, single-output systems, the authors offer a clear, conceptual presentation of adaptive methods, enabling a critical evaluation of these techniques and suggesting avenues of further development.},
	author = {Sastry, Shankar and Bodson, Marc and Bartram, James F.},
	doi = {10.1121/1.399905},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	title = {{Adaptive Control: Stability, Convergence, and Robustness}},
	year = {1990}
}

@article{Tanaskovic2014,
	abstract = {An adaptive control algorithm for open-loop stable, constrained, linear, multiple input multiple output systems is presented. The proposed approach can deal with both input and output constraints, as well as measurement noise and output disturbances. The adaptive controller consists of an iterative set membership identification algorithm, that provides a set of candidate plant models at each time step, and a model predictive controller, that enforces input and output constraints for all the plants inside the model set. The algorithm relies only on the solution of standard convex optimization problems that are guaranteed to be recursively feasible. The experimental results obtained by applying the proposed controller to a quad-tank testbed are presented.},
	author = {Tanaskovic, Marko and Fagiano, Lorenzo and Smith, Roy and Morari, Manfred},
	doi = {10.1016/j.automatica.2014.10.036},
	issn = {00051098},
	journal = {Automatica},
	keywords = {Adaptive control,Control of constrained systems,Impulse response,Learning control,Model predictive control,Self tuning control,Set membership identification},
	title = {{Adaptive receding horizon control for constrained MIMO systems}},
	year = {2014}
}

@Article{Lorenzen2017,
	author={Lorenzen, Matthias
	and Allg{\"o}wer, Frank
	and Cannon, Mark},
	title={Adaptive Model Predictive Control with Robust Constraint Satisfaction},
	journal={IFAC-PapersOnLine},
	year={2017},
	month={Jul},
	day={01},
	volume={50},
	number={1},
	pages={3313-3318},
	keywords={Model Predictive Control; Adaptive Control; Constraint Satisfaction Problems; Uncertain Linear Systems; System Identification},
	abstract={Adaptive control for constrained, linear systems is addressed and a solution based on Model Predictive Control (MPC) and set-membership system identification is presented. The paper introduces a computationally tractable solution which uses observations of past state and input trajectories to update the model and improve control performance while maintaining guaranteed constraint satisfaction and recursive feasibility. The developed approach is applied to a stabilizing MPC scheme and practical stability under persistent, additive disturbance is proved. A numerical example and brief comparison with non-adaptive MPC is provided.},
	issn={2405-8963}
}

@INPROCEEDINGS{Kohler2019,
	author={J. {Köhler} and E. {Andina} and R. {Soloperto} and M. A. {Müller} and F. {Allgöwer}},
	booktitle={2019 IEEE 58th Conference on Decision and Control (CDC)}, 
	title={Linear robust adaptive model predictive control: Computational complexity and conservatism}, 
	year={2019},
	volume={},
	number={},
	pages={1383-1388},}

@inproceedings{Lu2019,
	abstract = {An adaptive Model Predictive Control (adaptive MPC) strategy is proposed for linear systems with constant unknown model parameters, bounded additive disturbances and state and control constraints. By combining online set-based identification and robust tube MPC, the proposed controller reduces the conservativeness of constraint handling, guarantees recursive feasibility and provides asymptotic bounds on the closed loop system state that depend explicitly on the the identified parameter set. Computational tractability is ensured by using fixed complexity polytopic sets to bound the model parameters and predicted states. Convex conditions for persistence of excitation are considered. The results are illustrated by a numerical example.},
	author = {Lu, Xiaonan and Cannon, Mark},
	booktitle = {Proceedings of the American Control Conference},
	isbn = {9781538679265},
	issn = {07431619},
	title = {{Robust adaptive tube model predictive control}},
	year = {2019}
}
